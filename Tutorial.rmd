---
title: "EDA"
output: rmarkdown::github_document
author: "Muhammad"
date: "10/10/2021"
---

#Foundations of Exploratory Data Analysis



```{r}
# set working directory
setwd("C:/Users/mxa1132-admin/OneDrive/Documents/life-history-traits-analysis")
```



```{r}

# load libraries
library(readxl) # for reading excel files, both .xls and .xlsx.
library(dplyr) # for data manipulation
library(ggplot2) # for data visualization
library(lmerTest) # for linear mixed effects models
library(heplots) # for visualizing linear mixed effects models
library(rcompanion) # for calculating effect sizes and summarizing statistics.

```


```{r}
# read in data
Data <- read_excel(file.choose(), sheet = "MP")
#Data <- read_excel("C:/Users/mxa1132-admin/OneDrive/Documents/life-history-traits-analysis/MP.xlsx", sheet = "MP-Tia")

# the code uses read_excel() function from the readxl package to read an Excel file located in the working directory.
# the file.choose() function allows you to select the file interactively.
# Additionally, the sheet argument specifies the sheet name to be read. If the sheet argument is not specified, the first sheet in the Excel file will be read by default.
```


```{r}
# check data
Data
```


```{r}
# check data structure
str(Data) 
# check data structure e.g array, matrix, data frame, list, factor, character, integer, numeric, logical, etc.

# it provides a summary of the object, including the number of observations, variables, and variable names.

```

```{r}
# check data summary
summary(Data)

```

```{r}
# outliers detection
boxplot(Data$Fecundity, main = "Fecundity", ylab = "fecundity", col = "lightblue", border = "brown", vertical = TRUE)
```
What does the whiskers represents?

```{r}
# create a boxplot for both control and treatment groups (fecundity))

p <- ggplot(Data, aes(x = Treatment, y = Fecundity, fill = Treatment)) +
 
   geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 3) +
  
  labs(x = "Treatment", y = "Fecundity") +
  
  theme_bw() +
  
  theme(legend.position = "none")+
  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
print(p)
```

# Age_maturity
```{r}
# create a boxplot for both control and treatment groups (Age_maturity))
A <- ggplot(Data, aes(x = Treatment, y = Age_maturity, fill = Treatment)) +
  
  geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 3) +
  
  scale_color_manual(values = c("contro" = "red", "PET" = "blue")) +
  
  scale_fill_manual(values = c("control" = "lightblue", "PET" = "lightgreen")) +
  
  theme(legend.key.size = unit(0.5, "cm")) +
  
  labs(x = "Treatment", y = "Age_maturity") +
  
  scale_y_continuous(limits = c(1, 12)) +
  
  theme_minimal() 
  
  #theme(legend.position = "none")+
  
 # theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
print(A)

```



```{r}

# create a boxplot for both control and treatment groups (Size_maturity))

s <- ggplot(Data, aes(x = Treatment, y = Size_maturity, fill = Treatment)) +
  
  geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 3) +
  
  scale_color_manual(values = c("control" = "red", "PET" = "blue")) +
  
  scale_fill_manual(values = c("control" = "lightblue", "PET" = "lightgreen")) +
  
  theme(legend.key.size = unit(0.5, "cm")) +
  
  labs(x = "Treatment", y = "Size_maturity") +
  
  #scale_y_continuous(limits = c(1, 12)) +
  
  theme_minimal() 
  
  #theme(legend.position = "none")+
  
 # theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
print(s)

```

```{r}
# create a boxplot for both control and treatment groups (interval_broods))

IB <- ggplot(Data, aes(x = Treatment, y = Interval_brood, fill = Treatment)) +
  
  geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 3) +
  
  scale_color_manual(values = c("control" = "red", "PET" = "blue")) +
  
  scale_fill_manual(values = c("control" = "lightblue", "PET" = "lightgreen")) +
  
  theme(legend.key.size = unit(0.5, "cm")) +
  
  labs(x = "Treatment", y = "interval_broods") +
  
  #scale_y_continuous(limits = c(1, 12)) +
  
  theme_minimal() 
  
  #theme(legend.position = "none")+
  
 # theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
print(IB)

```


```{r}
# lets use the PCA to fish out the outliers.
# PCA is a dimensionality reduction technique that is often used to transform a high-dimensional dataset into a smaller-dimensional subspace prior to running a machine learning algorithm on the data.

# PCA is an unsupervised algorithm that learns the principal components of the data.

```

```{r}
# PCA: only works with numeric data
colSums(is.na(Data)) # check for missing values


```


```{r}
D <- Data 

print(D)
```
```{r}

D$Genotypes <- factor(D$Genotypes, levels = c("LRV-0-1", "LR2-36-01")) # convert Genotype to factor.

# Doing this will ensure that Genotype is treated as a categorical variable when we run the PCA.

# by defining the levels, we can control the order in which the levels are plotted.

# it will also help in performing comparisons between the levels of the factor.

```

```{r}
D$Treatment <- factor(D$Treatment, levels = c("control", "PET")) # convert Treatment to factor.
```


```{r}
D <- D[, c(1,2,3,4,7,10:11)] # select columns 1 to 4, 7, 10 and 11
```

```{r}
D
```

```{r}
comp_D <- D[complete.cases(D),] # remove missing values in rows

# complete.cases() function returns a logical vector indicating which cases are complete, i.e. have no missing values.

# we use this logical vector to subset the data frame and remove the rows with missing values.

# a logical vector is a vector that contains only TRUE and FALSE values or NA values.

# logical vectors are often used to subset data frames.

```

```{r}
comp_D
```


```{r}

comp_D_without_NA <- comp_D

print(comp_D_without_NA)
```


```{r}
comp_D_without_NA[4:7] <- log(comp_D_without_NA[4:7] + 0.5) # log transform columns 4 to 7

# takes the natural logarithm of the values in columns 4 to 7 and adds 0.5 to each value before taking the log.

# adding 0.5 to each value ensures that the log is taken for all values, even if the value is 0.

# the addition of 0.5 is a common practice when log transforming count data.

```

```{r}
print(comp_D_without_NA) 
```

```{r}
log_comp_D_WO_Na <- comp_D_without_NA[, c(4:7)] # select columns 4 to 7

# Creats a new data frame with only columns 4 to 7.

# we will use this data frame to run the PCA.

```

```{r}

print(log_comp_D_WO_Na)
```


```{r}
# run the PCA with variable scaling on the transformed data

pca <- prcomp(log_comp_D_WO_Na, scale = TRUE) # scale = TRUE scales the variables to have unit variance before running the PCA.

# prcomp() function from stat package returns a list of principal components using the log transformed data. 

# the scale = TRUE argument scales the variables to have unit variance before running the PCA.

# scaling the variables is important because variables with large variances can dominate the PCA.

# scaling the variables ensures that each variable contributes equally to the PCA.

# scaling is important when the variables are measured in different units.

# PCA is sensitive to the scale of the variables.

# the object is stored in the variable pca containing the following components: stdev, rotation,& principal components scores.

```

```{r}
# explaining PCA

# the principal components are linear combinations of the original variables.

# each priincipal component score provides information about the position of the observation in the principal component space.

# these scores are used to understand the relationship between the observations and patterns in the data.
```

```{r}

print(pca)
```

```{r}
# what is the relatioship between the socres and variance of the data?

# the principal components are representing the directions of maximum variance in the data.

# Each PC captures a certain amount of variance in the data.

# the first PC captures the most variance, the second PC captures the second most variance, and so on.

# the larger the variance captured by a PC, the more information it contains about the data.

# the Pcs are ordered by the amount of variance they capture.

# this relationship is important in PCA in understanding the contribution of each PC to the data.
```


```{r}
# how much variance is captured by each PC?

summary(pca) # the summary() function returns a summary of the PCA.
```



```{r}
Genotypes <- as.factor(comp_D_without_NA$Genotypes) # convert Genotype to factor

```

```{r}

Treatment <- as.factor(comp_D_without_NA$Treatment) # convert Treatment to factor

```

```{r}

# plot the scores for the first two PCs

library(factoextra) # load the factoextra package
library(FactoMineR) # load the FactoMineR package


```


```{r}


Pca_plot <- fviz_pca_ind(pca, habillage = Treatment, geom = "point") # fviz_pca_biplot() function from factoextra package is used to plot the scores for the first two PCs.
```

```{r}


print(Pca_plot)

```

```{r}

fviz_pca_biplot(pca,
             col.ind = Genotypes, # color by Genotype
            palette = c("LRV-0-1"="red","LR2-36-01"="black"), # color palette
              addEllipses = TRUE, # Concentration ellipses
              col.var="blue", # Variables color
              arrowsize=0.2, # Arrow size
             labelsize=3, # Label size
             geom.ind = "point", # show points only (nbut not "text")
             pointsize=1, # Point size
             pointshape=19, # Point shape
             mean.point=F,# Show mean point
            # xlim=c(-5,5),# x axis limits
             #ylim=c(-3,3), # y axis limits
             var.scale=0.5, # Scaling of the variables
             ellipse.type = "confidence", # Confidence ellipse
             legend.title = "Genotype", # Legend title
             repel = TRUE, # Avoid text overlapping
             )

```


```{r}

U <- pca$x

print(U)
```

```{r}
qplot(U[, 1], U[, 2], colour = factor(Treatment) ) + coord_equal() # plot the first two PCs
```

```{r}
#Measuring Outliers
apply(U, 2, function(x) which( abs(x - mean(x)) > (3 * sd(x)) )) # find outliers

# applies a function to each column of the matrix U.

# the function finds the observations that are more than 3 standard deviations from the mean.

# '2' indicates that the function is applied to each column of the matrix U.

# which() function is used to identify the indices that satisfy the condition.
```

```{r}
apply(U, 2, function(x) which( abs(x - mean(x)) > (2 * sd(x)) )) # find outliers
```

```{r}

# Three standard deviations away from the mean is a statistical concept related to the spread of data in a normal distribution. 

# In a normal distribution, 99.7% of the data is within three standard deviations of the mean.

# The observations that are more than three standard deviations away from the mean are considered outliers.

# the observations that are more than three standard deviations away from the mean are considered outliers.

# the observations that are more than two standard deviations away from the mean are considered extreme values.
```

```{r}
# Tukeys method

# Tukey's method is a statistical method for identifying outliers.

# Tukey's method uses the interquartile range (IQR) to identify outliers.


```

```{r}

#U_no_outliers <- U

#outliers <- apply(U, 2, function(x) which( abs(x - mean(x)) > (3 * sd(x)) )) # find outliers

#for (i in 1:ncol(U)) {
 # U_no_outliers[outliers[, i], i] <- NA
#}
```

```{r}

#for (i in 1:ncol(U)) {
 # U_no_outliers[outliers[[i]], i] <- NA
#}
```

```{r}
U_no_outliers 

```
```{r}

qplot(U_no_outliers[, 1], U_no_outliers[, 2], colour = factor(Genotype) ) + coord_equal()
```